{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python374jvsc74a57bd0a0947237fadc8b5561fed326db280cc5ec46a670c87cfb3a0489cf95ff262303",
   "display_name": "Python 3.7.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "a0947237fadc8b5561fed326db280cc5ec46a670c87cfb3a0489cf95ff262303"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. \n",
    "\n",
    "En el archivo \"logistic_regression_df_class\" hemos visto un ejemplo multiclase. Elimina del dataframe todas las filas que se correspondan con la clase valor \"1\".\n",
    "\n",
    "Ahora, realiza el ejercicio con el nuevo dataframe:\n",
    "\n",
    "- ¿Se mejora la precisión del algoritmo con dos clases? ¿por qué?\n",
    "\n",
    "LogisticRegression() es una clase que tiene varios parámetros de entrada. Investiga (modifica, prueba) los argumentos y comenta si modificando algunas de ellas se mejora el porcentaje de acierto del problema (probar al menos 2 diferentes)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"../data/usuarios_win_mac_lin.csv\")\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.clase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.drop(dataframe[dataframe.clase == 1].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.clase.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "y: (130,)\nX: (130, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(dataframe.drop(['clase'], axis=1))\n",
    "y = np.array(dataframe['clase'])\n",
    "print('y:', y.shape)\n",
    "print('X:', X.shape)"
   ]
  },
  {
   "source": [
    "## Validación del modelo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.81818182 1.         0.81818182 0.90909091 1.         1.\n 0.8        0.9        0.9        1.        ]\n----------\nLogistic Regression: 0.914545 +- (0.078330)\n----------\n----------\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=100)\n",
    "name='Logistic Regression'\n",
    "kfold = KFold(n_splits=10, random_state = seed, shuffle = True) #Parte los datos en 10 trozos para usar validación cruzada / cross validation\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy',)\n",
    "msg = \"%s: %f %s (%f)\" % (name, cv_results.mean(), \"+-\", cv_results.std())\n",
    "print(cv_results)\n",
    "print(\"----------\")\n",
    "print(msg)\n",
    "print(\"----------\")\n",
    "print(\"----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "# Los porcentajes obtenidos en el Cross Validation me satisfacen, entonces, entreno los datos del conjunto TRAIN\n",
    "\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9519230769230769"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "# Veamos qué porcentaje de acierto tengo para mi conjunto TRAIN\n",
    "\n",
    "model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "# Veamos qué porcentaje de acierto tengo para mi conjunto TEST (éstos son los datos que yo no le di, y es importante que el valor sea al menos cercano a los obtenidos para CV y para el conjunto TRAIN)\n",
    "\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "source": [
    "Se verifica un buen porcentaje para el conjunto \"TEST\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para el conjunto TEST, el primer valor es el siguiente\n",
    "Y_test[0::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X_test)[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos si la predicción  es correcta\n",
    "model.predict(X_test[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La predicción fue correcta... pero, qué tan seguro estaba de esta predicción ??\n",
    "model.predict_proba(X_test[0:1])"
   ]
  },
  {
   "source": [
    "Ésto último nos dice que estuvo prácticamete un 100% seguro de que se trataba de una clase 0 y no 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Como era de esperar, se mejora el algoritmo cuando solo tenemos 2 clases porque hay menor variabilidad en los resultados. Al algoritmo le resulta más sencillo aprender patrones cuando se lo entrena con menos clases y relacionarlos con cada una de ellas."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Pruebas cambiando algunas variables:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seed: 2\nTest size: 0.2\nMax iter: 100\nNúmero splits: 15\n----------\nResultados de CV: [0.71428571 1.         1.         0.85714286 0.57142857 1.\n 1.         1.         1.         0.71428571 1.         0.85714286\n 0.85714286 1.         1.        ]\n----------\nLogistic Regression: 0.904762 +- (0.134687)\n----------\nScore TRAIN: 0.9711538461538461\nScore TEST: 0.9615384615384616\n----------\nValor de Y_test en 25: 0\nPredicción de Y_test: 0\nSeguridad en predicción de Y_test: [0.99791085 0.00208915]\n----------\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "ts = 0.2\n",
    "mi = 100\n",
    "ns = 15\n",
    "print('Seed:', seed)\n",
    "print('Test size:', ts)\n",
    "print('Max iter:', mi)\n",
    "print('Número splits:', ns)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=ts, random_state=seed)\n",
    "model = LogisticRegression(solver = 'liblinear', penalty= 'l2', max_iter=mi)\n",
    "name='Logistic Regression'\n",
    "kfold = KFold(n_splits=ns, random_state = seed, shuffle = True) #Parte los datos en 10 trozos para usar validación cruzada / cross validation\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy',)\n",
    "msg = \"%s: %f %s (%f)\" % (name, cv_results.mean(), \"+-\", cv_results.std())\n",
    "print(\"----------\")\n",
    "print('Resultados de CV:', cv_results)\n",
    "print(\"----------\")\n",
    "print(msg)\n",
    "print(\"----------\")\n",
    "model.fit(X_train, Y_train)\n",
    "print('Score TRAIN:', model.score(X_train, Y_train))\n",
    "print('Score TEST:', model.score(X_test, Y_test))\n",
    "print(\"----------\")\n",
    "Y_test_random = random.randint(0,len(Y_test)-1)\n",
    "print('Valor de Y_test en ' + str(Y_test_random) + ':', Y_test[Y_test_random])\n",
    "print('Predicción de Y_test:', model.predict(X_test)[Y_test_random])\n",
    "print('Seguridad en predicción de Y_test:', model.predict_proba(X_test)[Y_test_random])\n",
    "print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Seed: 2\nTest size: 0.15\nMax iter: 200\nNúmero splits: 10\n----------\nResultados de CV: [1.         0.90909091 1.         1.         0.90909091 1.\n 0.72727273 0.90909091 0.90909091 1.        ]\n----------\nLogistic Regression: 0.936364 +- (0.081818)\n----------\nScore TRAIN: 0.9545454545454546\nScore TEST: 0.95\n----------\nValor de Y_test en 0: 0\nPredicción de Y_test: 0\nSeguridad en predicción de Y_test: [9.99999675e-01 3.25224113e-07]\n"
     ]
    }
   ],
   "source": [
    "seed = 2\n",
    "ts = 0.15\n",
    "mi = 200\n",
    "ns = 10\n",
    "print('Seed:', seed)\n",
    "print('Test size:', ts)\n",
    "print('Max iter:', mi)\n",
    "print('Número splits:', ns)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=ts, random_state=seed)\n",
    "model = LogisticRegression(max_iter=mi)\n",
    "name='Logistic Regression'\n",
    "kfold = KFold(n_splits=ns, random_state = seed, shuffle = True) #Parte los datos en 10 trozos para usar validación cruzada / cross validation\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy',)\n",
    "msg = \"%s: %f %s (%f)\" % (name, cv_results.mean(), \"+-\", cv_results.std())\n",
    "print(\"----------\")\n",
    "print('Resultados de CV:', cv_results)\n",
    "print(\"----------\")\n",
    "print(msg)\n",
    "print(\"----------\")\n",
    "model.fit(X_train, Y_train)\n",
    "print('Score TRAIN:', model.score(X_train, Y_train))\n",
    "print('Score TEST:', model.score(X_test, Y_test))\n",
    "print(\"----------\")\n",
    "Y_test_random = random.randint(0,len(Y_test)-1)\n",
    "print('Valor de Y_test en ' + str(Y_test_random) + ':', Y_test[Y_test_random])\n",
    "print('Predicción de Y_test:', model.predict(X_test)[Y_test_random])\n",
    "print('Seguridad en predicción de Y_test:', model.predict_proba(X_test)[Y_test_random])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2\n",
    "ts = 0.15\n",
    "mi = 200\n",
    "ns = 30\n",
    "print('Seed:', seed)\n",
    "print('Test size:', ts)\n",
    "print('Max iter:', mi)\n",
    "print('Número splits:', ns)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=ts, random_state=seed)\n",
    "model = LogisticRegression(max_iter=mi)\n",
    "name='Logistic Regression'\n",
    "kfold = KFold(n_splits=ns, random_state = seed, shuffle = True) #Parte los datos en 10 trozos para usar validación cruzada / cross validation\n",
    "cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy',)\n",
    "msg = \"%s: %f %s (%f)\" % (name, cv_results.mean(), \"+-\", cv_results.std())\n",
    "print(\"----------\")\n",
    "print('Resultados de CV:', cv_results)\n",
    "print(\"----------\")\n",
    "print(msg)\n",
    "print(\"----------\")\n",
    "model.fit(X_train, Y_train)\n",
    "print('Score TRAIN:', model.score(X_train, Y_train))\n",
    "print('Score TEST:', model.score(X_test, Y_test))\n",
    "print(\"----------\")\n",
    "Y_test_random = random.randint(0,len(Y_test)-1)\n",
    "print('Valor de Y_test en ' + str(Y_test_random) + ':', Y_test[Y_test_random])\n",
    "print('Predicción de Y_test:', model.predict(X_test)[Y_test_random])\n",
    "print('Seguridad en predicción de Y_test:', model.predict_proba(X_test)[Y_test_random])"
   ]
  }
 ]
}